c<- data.frame(
  name = c("Raina", "Bravo", "Dhoni", "Virat"),
  score = c(67, 56, 87, 91)
)
c$team<-c("csk","csk","csk","csk")
c
dim(c)
str(c)

h=c(7,12,28,3,41)
m=c('mar', 'apr', 'may', 'jun', 'jul')
barplot(h~m,xlab="xassjnnauf",ylab="hhbf",main="Remainder chart")

v1<-c(151, 174, 138, 186, 128, 136, 179, 163, 152, 131)
v2<-c(63, 81, 56, 91, 47, 57, 76, 72, 62, 48)
l=lm(v2~v1)
plot(v1,v2)
abline(l,col="red")
p<-predict(l,data.frame(v1=170))
p


s<-1
repeat{
  print(s)
  s<-s+1
  if(s>10){
    break
  }
}

df <- data.frame(
  ID = c(110, 220, 330, 440),
  Items = c("book", "pen", "textbook", "Color pen"),
  Store = c(TRUE, FALSE, TRUE, FALSE),
  Price = c(2.5, 8.0, 10.0, 25.0)
)
c<-df[,2]
c
f<-df[1:2,]
f


a<-c(13, 15, 16, 16, 19, 20, 20, 21, 22,
     22, 25, 25, 25, 25, 30, 33, 33, 35,35,
     35, 35, 36, 40, 45, 46, 52, 70)
f<-table(a)
m=as.numeric(names(f)[f==max(f)])
m

f<-function(n){
  if(n==0|| n==1){
    return(n)
  }
  return(f(n-1)+f(n-2))
}
n<-5
a<-sapply(0:n-1,f)
a


v<-c(9,13,21,8,36,22,12,41,31,33,19)
hist(v,xlab="xcbzszs",ylab="yjhadgiya",main="jhsdyeeadf",xlib=c(0,4),ylib=c(0,20))

d <- c(21, 62, 10, 53)
l <- c('London', 'New York', 'Singapore', 'Mumbai')
pie(d,labels=l,main="dvssfhj")
legend('topright',legend=l,title='jhusrv')

a<- matrix(c(2, 0, 1, 3), ncol = 2)
b<- matrix(c(5, 2, 4, 1), ncol = 2)
a+b
a-b
a%*%t(b)
abs(a)

n<-matrix(c(1:10,21:30),nrow=5)
n
m<-apply(a,1,mean)
median(n)
sum(n[,1:2])

e<- data.frame(
  Name = c("John", "Alice", "Bob"),
  Age = c(25, 30, 22),
  Score = c(85, 92, 78)
)
n <- data.frame(
  Name = c("Eva", "Chris"),
  Age = c(28, 35),
  Score = c(90, 88)
)
m<-rbind(e,n)
m

a<-1:9
b<-10:18
a<-array(c(a,b),dim=c(3,3,2))
s<-a[,,1]+a[,,2]
s

f<- data.frame(
  Surname = c("Smith", "Johnson", "Williams", "Jones", "Brown", "Davis", "Miller"),
  Nationality = c("US", "UK", "Canada", "Australia", "US", "UK", "Canada")
)
s<- data.frame(
  Surname = c("Smith", "Johnson", "Williams", "Jones", "Brown", "Davis", "Miller"),
  Movies = c(5, 8, 3, 6, 2, 7, 4)
)
m<-merge(f,s,by="Surname")
m
dim(m)

r<-c(9,8,7,6,5,4,3,2,1)
max(r)-min(r)

library(stringr)
m<-tolower("matrix")
c<-str_count(m,"[aeiou]")
c

v <- c(90, 50, 70, 80, 70, 60, 20, 30, 80, 90, 
            20, 75, 70, 10, 60, 70, 85, 95, 55, 15)
a<-sort(v)
l<-length(v)
a[4]
a[l-1]


f<-function(n){
  if(n==0||n==1){
    return(n)
  }
  return(n*f(n-1))
}
n<-5
a<-f(n)
a

data("political Knowledge")
pie("political Knowledge")
#plotly
#subplot(pie)

m<-matrix(c(1:16), nrow=4,byrow = TRUE)
m
m[2,3]
m[3,]
m[,4]


set.seed(123)
a<-as.factor(sample(LETTERS,100,replace=TRUE))
b<-levels(a)
sample(b,5)

#titanic:
# Load the Titanic dataset
data("Titanic")

# Convert the table to a data frame
titanic_df <- as.data.frame(Titanic)

# Bar chart
barplot(titanic_df$Freq, beside = TRUE, col = c("lightblue", "lightgreen"), 
        main = "Survival on Titanic by Passenger Class",
        xlab = "Passenger Class", ylab = "Frequency",
        legend.text = rownames(titanic_df), args.legend = list(title = "Survived"))

# Subset data for survived passengers
survived_df <- subset(titanic_df, Survived == "Yes")

# Bar chart for survived passengers based on gender
barplot(survived_df$Freq, beside = TRUE, col = c("lightblue", "lightgreen"), 
        main = "Survival on Titanic by Gender",
        xlab = "Gender", ylab = "Frequency",
        legend.text = rownames(survived_df), args.legend = list(title = "Survived"))

# Load necessary libraries
library(ggplot2)

# Extract the Age column from the Titanic dataset
age_data <- as.vector(Titanic[, , , "Age"])

# Plot histogram
ggplot(data.frame(Age = age_data), aes(x = Age)) +
  geom_histogram(binwidth = 5, fill = "lightblue", color = "black", alpha = 0.7) +
  labs(title = "Distribution of Age on Titanic", x = "Age", y = "Frequency")

  #iris
  # Load necessary libraries
library(dplyr)
library(caTools)
library(nnet)

# Load iris dataset
data(iris)

# Select relevant columns
iris_subset <- iris %>%
  select(Species, Petal.Length, Petal.Width)

# Set seed for reproducibility
set.seed(123)

# Split the dataset into training (80%) and testing (20%) sets
split <- sample.split(iris_subset$Species, SplitRatio = 0.8)
train_data <- subset(iris_subset, split == TRUE)
test_data <- subset(iris_subset, split == FALSE)

# Create logistic regression model
log_reg_model <- multinom(Species ~ Petal.Length + Petal.Width, data = train_data)

# Predict the probabilities on the test set
predicted_probs <- predict(log_reg_model, newdata = test_data, type = "probs")

# Convert predicted probabilities to predicted classes
predicted_classes <- colnames(predicted_probs)[apply(predicted_probs, 1, which.max)]

# Create a confusion matrix
conf_matrix <- table(Actual = test_data$Species, Predicted = predicted_classes)
print("Confusion Matrix:")
print(conf_matrix)
#12 random
# Set seed for reproducibility
set.seed(123)

# Create a 3x4 matrix with random numbers between 1-100
original_matrix <- matrix(sample(1:100, 12), nrow = 3, ncol = 4, byrow = TRUE)

# Name the columns and rows
colnames(original_matrix) <- c("uno", "dos", "tres", "cuatro")
rownames(original_matrix) <- c("x", "y", "z")

# Scale the matrix by 10
scaled_matrix <- original_matrix * 10

# Print the original and scaled matrices
print("Original Matrix:")
print(original_matrix)
print("Scaled Matrix:")
print(scaled_matrix)
# Extract the column "uno" as a vector
column_uno <- original_matrix[, "uno"]
print("Vector from Column 'uno':")
print(column_uno)
# Extract the row 'y' as a vector
row_y <- original_matrix["y", ]
print("Vector from Row 'y':")
print(row_y)

# Print the sum of the vector
cat("Sum of the vector from Row 'y':", sum(row_y), "\n")

#usa
# Load the necessary library
library(datasets)

# Load the USArrests dataset
data("USArrests")

# (i) 
# a. Explore the summary of the dataset
cat("Number of Features:", ncol(USArrests), "\n")
cat("Number of Records for Each Feature:\n")
print(colSums(!is.na(USArrests)))

# Print the statistical features of the data
summary(USArrests)

# b. Print the state which saw the largest total number of rape
state_max_rape <- rownames(USArrests)[which.max(USArrests$Rape)]
cat("State with the largest total number of rape:", state_max_rape, "\n")

# c. Print the states with the max & min crime rates for murder
state_max_murder <- rownames(USArrests)[which.max(USArrests$Murder)]
state_min_murder <- rownames(USArrests)[which.min(USArrests$Murder)]

cat("State with the max crime rate for murder:", state_max_murder, "\n")
cat("State with the min crime rate for murder:", state_min_murder, "\n")

# (ii)
# a. Find the correlation among the features
correlation_matrix <- cor(USArrests)
cat("Correlation Matrix:\n")
print(correlation_matrix)

# b. Print the states which have assault arrests more than the median of the country
assault_median <- median(USArrests$Assault)
states_above_median_assault <- rownames(USArrests)[USArrests$Assault > assault_median]

cat("States with assault arrests more than the median of the country:", states_above_median_assault, "\n")

# c. Print the states that are in the bottom 25% of murder
murder_25_percentile <- quantile(USArrests$Murder, 0.25)
states_bottom_25_percent_murder <- rownames(USArrests)[USArrests$Murder < murder_25_percentile]

cat("States in the bottom 25% of murder:", states_bottom_25_percent_murder, "\n")
#maxi
# Given commute times
commute_times <- c(17, 16, 20, 24, 22, 15, 21, 15, 17, 22)

# a. Functions to find the maximum, average, and minimum commute times
maxi <- function(times) {
  max_time <- max(times)
  cat("Maximum commute time:", max_time, "\n")
  return(max_time)
}

avger <- function(times) {
  avg_time <- mean(times)
  cat("Average commute time:", avg_time, "\n")
  return(avg_time)
}

mini <- function(times) {
  min_time <- min(times)
  cat("Minimum commute time:", min_time, "\n")
  return(min_time)
}

# Apply the functions
max_commute_time <- maxi(commute_times)
avg_commute_time <- avger(commute_times)
min_commute_time <- mini(commute_times)

# b. Fix the mistake (24 should be 18)
commute_times[which(commute_times == 24)] <- 18

# Find the new average after fixing the mistake
new_avg_commute_time <- avger(commute_times)

# c. Count how many times the commute was 20 minutes or more
times_20_or_more <- sum(commute_times >= 20)
cat("Number of times the commute was 20 minutes or more:", times_20_or_more, "\n")
#6X10
# Set seed for reproducibility
set.seed(123)

# a. Create a 6 × 10 matrix of random integers in the range of 1:10
random_matrix <- matrix(sample(1:10, 6 * 10, replace = TRUE), nrow = 6, ncol = 10)

# Print the random matrix
cat("Random Matrix:\n")
print(random_matrix)

# b. Find the number of entries in each row which are greater than 4
entries_greater_than_4 <- apply(random_matrix, 1, function(row) sum(row > 4))
cat("Number of entries greater than 4 in each row:\n")
print(entries_greater_than_4)

# c. Which rows contain exactly two occurrences of the number 7
rows_with_two_7 <- which(apply(random_matrix == 7, 1, sum) == 2)
cat("Rows containing exactly two occurrences of the number 7:\n")
print(rows_with_two_7)
#air
# Load the airquality dataset
data("airquality")

# Check if it is a data frame
if (is.data.frame(airquality)) {
  cat("airquality is a data frame.\n")

  # Order the data frame by the first and second column
  ordered_airquality <- airquality[order(airquality$Month, airquality$Day), ]

  # Print the ordered data frame
  cat("Ordered airquality data frame by Month and Day:\n")
  print(ordered_airquality)
} else {
  cat("airquality is not a data frame.\n")
}
#air2
# Load necessary libraries
library(reshape2)
library(ggplot2)

# Load 'airquality' dataset
data("airquality")

# a. Melt 'airquality' dataset and display as a long-format data
melted_airquality_a <- melt(airquality)
cat("a. Melted 'airquality' dataset (long-format data):\n")
print(melted_airquality_a)

# b. Melt 'airquality' data and specify month and day to be “ID variables”
melted_airquality_b <- melt(airquality, id.vars = c("Month", "Day"))
cat("b. Melted 'airquality' dataset with Month and Day as ID variables:\n")
print(melted_airquality_b)

# c. Cast the molten 'airquality' data set
casted_airquality <- dcast(melted_airquality_b, Month + Day ~ variable, value.var = "value")
cat("c. Casted 'airquality' dataset:\n")
print(casted_airquality)

# d. Use cast function appropriately and compute the average of Ozone, Solar, Wind, and temperature per month
average_per_month <- dcast(melted_airquality_a, Month ~ variable, fun.aggregate = mean)
cat("d. Average of Ozone, Solar, Wind, and Temperature per month:\n")
print(average_per_month)

# e. Create a boxplot for ozone reading of 'airquality' dataset. Add title, label, and color.
ggplot(airquality, aes(x = factor(Month), y = Ozone, fill = factor(Month))) +
  geom_boxplot() +
  labs(title = "Boxplot for Ozone Reading", x = "Month", y = "Ozone Reading") +
  theme_minimal() +
  scale_fill_brewer(palette = "Set3")

#chick
# Load necessary libraries
library(reshape2)
library(ggplot2)

# Load ChickWeight dataset
data("ChickWeight")

# (i) Order the data frame by "weight" in ascending order, grouped by "Diet"
ordered_chickweight <- ChickWeight[order(ChickWeight$Diet, ChickWeight$weight), ]

# Extract the last 6 records from the ordered data frame
last_six_records <- tail(ordered_chickweight, 6)
cat("(i) Last 6 records from ordered data frame:\n")
print(last_six_records)

# (ii) 
# a. Perform melting function based on "Chick", "Time", "Diet" features as ID variables
melted_chickweight <- melt(ChickWeight, id.vars = c("Chick", "Time", "Diet"))

# b. Perform cast function to display the mean value of weight grouped by Diet
mean_weight_by_diet <- dcast(melted_chickweight, Diet ~ variable, mean)
cat("(ii) b. Mean value of weight grouped by Diet:\n")
print(mean_weight_by_diet)

# c. Perform cast function to display the mode of weight grouped by Diet
mode_weight_by_diet <- dcast(melted_chickweight, Diet ~ variable, function(x) {
  tbl <- table(x)
  mode_value <- as.numeric(names(tbl)[which.max(tbl)])
  return(mode_value)
})
cat("(ii) c. Mode of weight grouped by Diet:\n")
print(mode_weight_by_diet)

# (iii)
# a. Create Box plot for "weight" grouped by "Diet"
ggplot(ChickWeight, aes(x = as.factor(Diet), y = weight)) +
  geom_boxplot() +
  labs(title = "Box plot for Weight grouped by Diet", x = "Diet", y = "Weight")

# b. Create a Histogram for "weight" features belonging to Diet-1 category
ggplot(ChickWeight[ChickWeight$Diet == 1, ], aes(x = weight)) +
  geom_histogram(fill = "lightblue", color = "black", bins = 15) +
  labs(title = "Histogram for Weight (Diet-1)", x = "Weight", y = "Frequency")

# c. Create Scatter plot for "weight" vs "Time" grouped by Diet
ggplot(ChickWeight, aes(x = Time, y = weight, color = as.factor(Diet))) +
  geom_point() +
  labs(title = "Scatter plot for Weight vs Time grouped by Diet", x = "Time", y = "Weight")

